{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OZ3cMyTfYwNbRgZ7ZcntVvEpDwZx7zaQ",
      "authorship_tag": "ABX9TyNq+PqoHdATgoK9AVAKeR0d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlviyuli/SentimenAnalisisLSTM/blob/main/Tahap_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0NV8Ao7qjYv",
        "outputId": "46e0a267-2470-48e9-b042-4886a6b1648a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # Menonaktifkan peringatan chaining\n",
        "import numpy as np  # NumPy untuk komputasi numerik\n",
        "seed = 0\n",
        "np.random.seed(seed)  # Mengatur seed untuk reproduktibilitas\n",
        "import matplotlib.pyplot as plt  # Matplotlib untuk visualisasi data\n",
        "import seaborn as sns  # Seaborn untuk visualisasi data statistik, mengatur gaya visualisasi\n",
        "\n",
        "import datetime as dt  # Manipulasi data waktu dan tanggal\n",
        "import re  # Modul untuk bekerja dengan ekspresi reguler\n",
        "import string  # Berisi konstanta string, seperti tanda baca\n",
        "from nltk.tokenize import word_tokenize  # Tokenisasi teks\n",
        "from nltk.corpus import stopwords  # Daftar kata-kata berhenti dalam teks\n",
        "\n",
        "!pip install sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory  # Stemming (penghilangan imbuhan kata) dalam bahasa Indonesia\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  # Menghapus kata-kata berhenti dalam bahasa Indonesia\n",
        "\n",
        "from wordcloud import WordCloud  # Membuat visualisasi berbentuk awan kata (word cloud) dari teks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIR4mp1zq-5B",
        "outputId": "fa8f4c96-ea41-440b-b0da-18e14e92d26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/209.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menambahkan File Data"
      ],
      "metadata": {
        "id": "ZZkHZdLY03mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path ke file CSV\n",
        "path = '/content/drive/MyDrive/ulasan_aplikasi_jul_sep_2024 (ok).csv'\n",
        "\n",
        "# Daftar encoding yang akan dicoba\n",
        "encodings_to_try = [ 'ISO-8859-1', 'cp1252']\n",
        "\n",
        "# Periksa apakah DataFrame 'df' telah berhasil dibuat atau tidak.\n",
        "if 'df' in locals():\n",
        "    # Tampilkan beberapa baris pertama DataFrame jika berhasil\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"Gagal membaca file dengan semua encoding yang dicoba.\")"
      ],
      "metadata": {
        "id": "CUfZYz_-sUeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c9c70e-9275-44c7-8eb2-50f135b350e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gagal membaca file dengan semua encoding yang dicoba.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk  # Import pustaka NLTK (Natural Language Toolkit).\n",
        "nltk.download('punkt')  # Mengunduh dataset yang diperlukan untuk tokenisasi teks.\n",
        "nltk.download('stopwords')  # Mengunduh dataset yang berisi daftar kata-kata berhenti (stop words) dalam berbagai bahasa."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNEU_dHf1vud",
        "outputId": "2da945b3-a638-4225-fe53-2c3dd8a3859f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processing\n",
        "1. Cleaning"
      ],
      "metadata": {
        "id": "MCVyoYCnsex8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Fungsi untuk membersihkan teks\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\d+', '', text)  # Menghapus Angka\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Menghapus Tanda Baca\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Menghapus karakter non-ASCII (seperti emoji dan simbol khusus)\n",
        "    return text\n",
        "\n",
        "# Path ke file CSV\n",
        "path = '/content/drive/MyDrive/ulasan_aplikasi_jul_sep_2024 (ok).csv'  # Ganti dengan path file CSV Anda\n",
        "\n",
        "# Daftar encoding yang akan dicoba\n",
        "encodings_to_try = ['ISO-8859-1', 'cp1252','utf-8']\n",
        "df = None  # Initialize df to None\n",
        "\n",
        "# Coba membaca file dengan beberapa opsi penanganan encoding dan error\n",
        "for encoding in encodings_to_try:\n",
        "    try:\n",
        "        # Coba membaca file dengan encoding tertentu\n",
        "        df = pd.read_csv(path, sep=';', encoding=encoding)\n",
        "        print(f\"File berhasil dibaca dengan encoding: {encoding}\")\n",
        "        # Jika berhasil dibaca, berhenti mencoba encoding lain\n",
        "        break\n",
        "    except UnicodeDecodeError:\n",
        "        # Jika terjadi UnicodeDecodeError, coba encoding berikutnya\n",
        "        print(f\"Gagal membaca file dengan encoding: {encoding}\")\n",
        "    except pd.errors.ParserError:\n",
        "        print(f\"Gagal membaca file dengan encoding: {encoding} dan delimiter: ';'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Terjadi kesalahan: {e}\")\n",
        "\n",
        "if df is not None:\n",
        "    # Memeriksa apakah kolom 'riview' ada dalam data\n",
        "    if 'riview' in df.columns:\n",
        "        # Terapkan fungsi clean_text ke kolom 'riview'\n",
        "        df['cleaned_riview'] = df['riview'].apply(clean_text)\n",
        "\n",
        "        # Menampilkan beberapa hasil cleaning\n",
        "        print(\"Hasil cleaning:\")\n",
        "        print(df[['riview', 'cleaned_riview']].head(5))  # Menampilkan 5 baris pertama\n",
        "    else:\n",
        "        print(\"Kolom 'riview' tidak ditemukan dalam data.\")\n",
        "else:\n",
        "  print(\"Failed to read data with any encoding\")"
      ],
      "metadata": {
        "id": "4jKMuSvuuy1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72fc71b1-7647-442f-d035-1d8c33ebb466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File berhasil dibaca dengan encoding: ISO-8859-1\n",
            "Hasil cleaning:\n",
            "                                              riview  \\\n",
            "0  Sangat buruk , dimana mana orang pesan karna b...   \n",
            "1  Gk efektif. Diberikan resep obat, cuma bisa te...   \n",
            "2  Apk sy mengalami error, dimana saya sudah meng...   \n",
            "3  Sangat sangat tidak rekomendasi apalagi CS nya...   \n",
            "4  Baru seminggu d update,sudah minta update lagi...   \n",
            "\n",
            "                                      cleaned_riview  \n",
            "0  Sangat buruk  dimana mana orang pesan karna bu...  \n",
            "1  Gk efektif Diberikan resep obat cuma bisa tebu...  \n",
            "2  Apk sy mengalami error dimana saya sudah mengk...  \n",
            "3  Sangat sangat tidak rekomendasi apalagi CS nya...  \n",
            "4  Baru seminggu d updatesudah minta update lagih...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Case Folding"
      ],
      "metadata": {
        "id": "iBJwsi15C-6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk case folding (mengubah teks menjadi huruf kecil)\n",
        "def case_folding(text):\n",
        "    return text.lower()\n",
        "\n",
        "if 'riview' in df.columns:\n",
        "    def clean_text(text):\n",
        "        text = re.sub(r'\\d+', '', text) # Menghapus angka\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))  # Menghapus tanda baca\n",
        "        text = re.sub(r'[^\\x00-\\x7F]+', '', text) # Menghapus karakter non-ASCII (seperti emoji dan simbol khusus)\n",
        "        return text\n",
        "\n",
        "    df['cleaned_riview'] = df['riview'].apply(clean_text) # Membersihkan kolom 'review' terlebih dahulu\n",
        "\n",
        "   # Terapkan case folding pada kolom yang sudah dibersihkan\n",
        "    df['case_folded_riview'] = df['cleaned_riview'].apply(case_folding)\n",
        "\n",
        "    # Menampilkan beberapa contoh hasil case folding\n",
        "    print(\"Hasil case folding setelah cleaning:\")\n",
        "    print(df[['riview', 'cleaned_riview', 'case_folded_riview']].head(5))  # Menampilkan 10 baris pertama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5pQwHh3DBPL",
        "outputId": "6512a12e-f496-4351-f022-607a6a0e962a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil case folding setelah cleaning:\n",
            "                                              riview  \\\n",
            "0  Sangat buruk , dimana mana orang pesan karna b...   \n",
            "1  Gk efektif. Diberikan resep obat, cuma bisa te...   \n",
            "2  Apk sy mengalami error, dimana saya sudah meng...   \n",
            "3  Sangat sangat tidak rekomendasi apalagi CS nya...   \n",
            "4  Baru seminggu d update,sudah minta update lagi...   \n",
            "\n",
            "                                      cleaned_riview  \\\n",
            "0  Sangat buruk  dimana mana orang pesan karna bu...   \n",
            "1  Gk efektif Diberikan resep obat cuma bisa tebu...   \n",
            "2  Apk sy mengalami error dimana saya sudah mengk...   \n",
            "3  Sangat sangat tidak rekomendasi apalagi CS nya...   \n",
            "4  Baru seminggu d updatesudah minta update lagih...   \n",
            "\n",
            "                                  case_folded_riview  \n",
            "0  sangat buruk  dimana mana orang pesan karna bu...  \n",
            "1  gk efektif diberikan resep obat cuma bisa tebu...  \n",
            "2  apk sy mengalami error dimana saya sudah mengk...  \n",
            "3  sangat sangat tidak rekomendasi apalagi cs nya...  \n",
            "4  baru seminggu d updatesudah minta update lagih...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan hasil pembersihan dan case folding ke file CSV baru\n",
        "df.to_csv('cleaned_and_case_folded_riview.csv', index=False)\n",
        "# Memberikan pesan bahwa file telah disimpan\n",
        "print(\"Hasil pembersihan dan case folding telah disimpan dalam 'cleaned_and_case_folded_riview.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl9NxZ-KKltw",
        "outputId": "a721c0ea-23a9-4b45-976e-cefe50c352d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil pembersihan dan case folding telah disimpan dalam 'cleaned_and_case_folded_riview.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Tokenizing"
      ],
      "metadata": {
        "id": "iJYi5qz0L6iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ3AjF4YTKjh",
        "outputId": "3f1c2764-55ce-43aa-d842-35ab44881062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenizingText(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def display_tokenization(text):\n",
        "    # Tokenisasi teks\n",
        "    tokens = tokenizingText(text)\n",
        "    # Menampilkan hasil tokenisasi\n",
        "    print(f\"Original Text: {text}\")\n",
        "    print(f\"Tokenized Text: {tokens}\\n\")"
      ],
      "metadata": {
        "id": "hj6zp80OL4aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Terapkan tokenisasi pada kolom 'case_folded_riview'\n",
        "df['tokenized_riview'] = df['case_folded_riview'].apply(tokenizingText)\n",
        "# Tampilkan hasil tokenisasi untuk 5 baris pertama\n",
        "for i in range(5):\n",
        "    display_tokenization(df['case_folded_riview'].iloc[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFVbtsuSS6Fd",
        "outputId": "9de10ca4-935c-41e4-a8f8-b16ceec109bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: sangat buruk  dimana mana orang pesan karna butuh cepat  tapi di aplikasi malah memperlama  perhari ini sudah lewat  hari dari yg di tentukan tapi obat pesanan belum juga sampai  chat denga cs tidak ada gunanya  sangat sangat slow respon  status pembayaran dari berhasil berubah menjadi gagal setelah di komplain ke aplikasi nya  halodoc very very bad \n",
            "Tokenized Text: ['sangat', 'buruk', 'dimana', 'mana', 'orang', 'pesan', 'karna', 'butuh', 'cepat', 'tapi', 'di', 'aplikasi', 'malah', 'memperlama', 'perhari', 'ini', 'sudah', 'lewat', 'hari', 'dari', 'yg', 'di', 'tentukan', 'tapi', 'obat', 'pesanan', 'belum', 'juga', 'sampai', 'chat', 'denga', 'cs', 'tidak', 'ada', 'gunanya', 'sangat', 'sangat', 'slow', 'respon', 'status', 'pembayaran', 'dari', 'berhasil', 'berubah', 'menjadi', 'gagal', 'setelah', 'di', 'komplain', 'ke', 'aplikasi', 'nya', 'halodoc', 'very', 'very', 'bad']\n",
            "\n",
            "Original Text: gk efektif diberikan resep obat cuma bisa tebus pakai aplikasi terus pilihan pengiriman cuman ada reguler  hari lha gimana orang butuh obatnya sekarang malah mesti nunggu berhari padahal apotiknya di dalam kota ajatp pengirimannya lambannnn harap diperbaiki lagi\n",
            "Tokenized Text: ['gk', 'efektif', 'diberikan', 'resep', 'obat', 'cuma', 'bisa', 'tebus', 'pakai', 'aplikasi', 'terus', 'pilihan', 'pengiriman', 'cuman', 'ada', 'reguler', 'hari', 'lha', 'gimana', 'orang', 'butuh', 'obatnya', 'sekarang', 'malah', 'mesti', 'nunggu', 'berhari', 'padahal', 'apotiknya', 'di', 'dalam', 'kota', 'ajatp', 'pengirimannya', 'lambannnn', 'harap', 'diperbaiki', 'lagi']\n",
            "\n",
            "Original Text: apk sy mengalami error dimana saya sudah mengkonfirmasi pembayaran akan tetapi berulang kali diminta otp tapi gagaltidak bisa masuk kembali ke apk halodoc kemudian sy lakukan pembatalan ternyata pembayaran sdh masuk dan tidak bisa refund sehingga sy harus melakukan x pembayaran untuk bisa menggunakan apk halodoc ini\n",
            "Tokenized Text: ['apk', 'sy', 'mengalami', 'error', 'dimana', 'saya', 'sudah', 'mengkonfirmasi', 'pembayaran', 'akan', 'tetapi', 'berulang', 'kali', 'diminta', 'otp', 'tapi', 'gagaltidak', 'bisa', 'masuk', 'kembali', 'ke', 'apk', 'halodoc', 'kemudian', 'sy', 'lakukan', 'pembatalan', 'ternyata', 'pembayaran', 'sdh', 'masuk', 'dan', 'tidak', 'bisa', 'refund', 'sehingga', 'sy', 'harus', 'melakukan', 'x', 'pembayaran', 'untuk', 'bisa', 'menggunakan', 'apk', 'halodoc', 'ini']\n",
            "\n",
            "Original Text: sangat sangat tidak rekomendasi apalagi cs nya beli obat lama banget sudah di konfirmasi sebelum jam  tapi apotiknya sampe tutup tidak kunjung dikirim sampai  jam lebih kurir sampe ganti berulangkali tapi sayang ga ada menu pembatalan\n",
            "Tokenized Text: ['sangat', 'sangat', 'tidak', 'rekomendasi', 'apalagi', 'cs', 'nya', 'beli', 'obat', 'lama', 'banget', 'sudah', 'di', 'konfirmasi', 'sebelum', 'jam', 'tapi', 'apotiknya', 'sampe', 'tutup', 'tidak', 'kunjung', 'dikirim', 'sampai', 'jam', 'lebih', 'kurir', 'sampe', 'ganti', 'berulangkali', 'tapi', 'sayang', 'ga', 'ada', 'menu', 'pembatalan']\n",
            "\n",
            "Original Text: baru seminggu d updatesudah minta update lagiheran padahal gk ada yg baru dari aplikasi nymasih tetap begitu aja kirain update ada fitur yg terbaruternyata tidakjadi yg d update itu apa tolong lebih d perhatikan kenapa selalu minta update\n",
            "Tokenized Text: ['baru', 'seminggu', 'd', 'updatesudah', 'minta', 'update', 'lagiheran', 'padahal', 'gk', 'ada', 'yg', 'baru', 'dari', 'aplikasi', 'nymasih', 'tetap', 'begitu', 'aja', 'kirain', 'update', 'ada', 'fitur', 'yg', 'terbaruternyata', 'tidakjadi', 'yg', 'd', 'update', 'itu', 'apa', 'tolong', 'lebih', 'd', 'perhatikan', 'kenapa', 'selalu', 'minta', 'update']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan DataFrame yang berisi hasil tokenisasi ke dalam file CSV\n",
        "df.to_csv('/content/tokenized_content.csv', index=False)\n",
        "# Memberikan pesan untuk memastikan file telah disimpan\n",
        "print(\"Hasil tokenisasi telah disimpan ke dalam '/content/tokenized_content.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmTocLQyU5r6",
        "outputId": "880ae3b0-b281-4023-ab94-2f880b5ebc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil tokenisasi telah disimpan ke dalam '/content/tokenized_content.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Stopword"
      ],
      "metadata": {
        "id": "bkwVaftRVOQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "def filteringText(tokens, stopwords_file=None):\n",
        "    # Daftar stopwords default dari NLTK\n",
        "    try:\n",
        "        listStopwords = set(stopwords.words('indonesian'))\n",
        "    except LookupError:\n",
        "        import nltk\n",
        "        nltk.download('stopwords')\n",
        "        listStopwords = set(stopwords.words('indonesian'))\n",
        "\n",
        "    # Tambahkan stopwords umum informal (non-negasi)\n",
        "    additional_stopwords = [\n",
        "        'yaa', 'yah', 'deh', 'nih', 'dong', 'aja', 'doang', 'tok', 'cuma',\n",
        "        'cmn', 'kok', 'loh', 'mah', 'pun', 'lah', 'tuh', 'kan', 'kayak',\n",
        "        'dah', 'ntar', 'trus', 'lagi', 'banget', 'bgt', 'makasih', 'makasi',\n",
        "        'makas', 'thanks', 'thx', 'pls', 'please', 'btw', 'wkwk', 'wkwkwk',\n",
        "        'haha', 'hehe', 'hmm', 'hadeh', 'eh', 'sip', 'ok', 'oke', 'yap',\n",
        "        'sumpah', 'fix', 'gitu', 'gimana', 'gini', 'gituan', 'biasa',\n",
        "        'biasanya', 'jadiin', 'emang', 'emg', 'ajaib', 'seringan', 'd', 'yg',\n",
        "        'sy', 'lha', 'very', 'x'\n",
        "    ]\n",
        "    listStopwords.update(additional_stopwords)\n",
        "\n",
        "    # Filtering token\n",
        "    filtered_tokens = [word for word in tokens if word not in listStopwords]\n",
        "    return filtered_tokens"
      ],
      "metadata": {
        "id": "eMEWs4obVQiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Terapkan stopword removal untuk setiap baris dalam tokenized riview\n",
        "df['filtered_riview'] = df['tokenized_riview'].apply(filteringText)\n",
        "\n",
        "for index, row in df.head(5).iterrows(): #tampilkan 5 baris awal\n",
        "    print(f\"Original Tokenized Text: {row['tokenized_riview']}\")\n",
        "    print(f\"Filtered Text (No Stopwords): {row['filtered_riview']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y51tyPF7Va8Z",
        "outputId": "7add276b-69be-4602-8fc7-1aae397d6e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokenized Text: ['sangat', 'buruk', 'dimana', 'mana', 'orang', 'pesan', 'karna', 'butuh', 'cepat', 'tapi', 'di', 'aplikasi', 'malah', 'memperlama', 'perhari', 'ini', 'sudah', 'lewat', 'hari', 'dari', 'yg', 'di', 'tentukan', 'tapi', 'obat', 'pesanan', 'belum', 'juga', 'sampai', 'chat', 'denga', 'cs', 'tidak', 'ada', 'gunanya', 'sangat', 'sangat', 'slow', 'respon', 'status', 'pembayaran', 'dari', 'berhasil', 'berubah', 'menjadi', 'gagal', 'setelah', 'di', 'komplain', 'ke', 'aplikasi', 'nya', 'halodoc', 'very', 'very', 'bad']\n",
            "Filtered Text (No Stopwords): ['buruk', 'dimana', 'orang', 'pesan', 'karna', 'butuh', 'cepat', 'aplikasi', 'memperlama', 'perhari', 'tentukan', 'obat', 'pesanan', 'chat', 'denga', 'cs', 'gunanya', 'slow', 'respon', 'status', 'pembayaran', 'berhasil', 'berubah', 'gagal', 'komplain', 'aplikasi', 'nya', 'halodoc', 'bad']\n",
            "\n",
            "\n",
            "Original Tokenized Text: ['gk', 'efektif', 'diberikan', 'resep', 'obat', 'cuma', 'bisa', 'tebus', 'pakai', 'aplikasi', 'terus', 'pilihan', 'pengiriman', 'cuman', 'ada', 'reguler', 'hari', 'lha', 'gimana', 'orang', 'butuh', 'obatnya', 'sekarang', 'malah', 'mesti', 'nunggu', 'berhari', 'padahal', 'apotiknya', 'di', 'dalam', 'kota', 'ajatp', 'pengirimannya', 'lambannnn', 'harap', 'diperbaiki', 'lagi']\n",
            "Filtered Text (No Stopwords): ['gk', 'efektif', 'resep', 'obat', 'tebus', 'pakai', 'aplikasi', 'pilihan', 'pengiriman', 'cuman', 'reguler', 'orang', 'butuh', 'obatnya', 'mesti', 'nunggu', 'berhari', 'apotiknya', 'kota', 'ajatp', 'pengirimannya', 'lambannnn', 'harap', 'diperbaiki']\n",
            "\n",
            "\n",
            "Original Tokenized Text: ['apk', 'sy', 'mengalami', 'error', 'dimana', 'saya', 'sudah', 'mengkonfirmasi', 'pembayaran', 'akan', 'tetapi', 'berulang', 'kali', 'diminta', 'otp', 'tapi', 'gagaltidak', 'bisa', 'masuk', 'kembali', 'ke', 'apk', 'halodoc', 'kemudian', 'sy', 'lakukan', 'pembatalan', 'ternyata', 'pembayaran', 'sdh', 'masuk', 'dan', 'tidak', 'bisa', 'refund', 'sehingga', 'sy', 'harus', 'melakukan', 'x', 'pembayaran', 'untuk', 'bisa', 'menggunakan', 'apk', 'halodoc', 'ini']\n",
            "Filtered Text (No Stopwords): ['apk', 'mengalami', 'error', 'dimana', 'mengkonfirmasi', 'pembayaran', 'berulang', 'kali', 'otp', 'gagaltidak', 'masuk', 'apk', 'halodoc', 'lakukan', 'pembatalan', 'pembayaran', 'sdh', 'masuk', 'refund', 'pembayaran', 'apk', 'halodoc']\n",
            "\n",
            "\n",
            "Original Tokenized Text: ['sangat', 'sangat', 'tidak', 'rekomendasi', 'apalagi', 'cs', 'nya', 'beli', 'obat', 'lama', 'banget', 'sudah', 'di', 'konfirmasi', 'sebelum', 'jam', 'tapi', 'apotiknya', 'sampe', 'tutup', 'tidak', 'kunjung', 'dikirim', 'sampai', 'jam', 'lebih', 'kurir', 'sampe', 'ganti', 'berulangkali', 'tapi', 'sayang', 'ga', 'ada', 'menu', 'pembatalan']\n",
            "Filtered Text (No Stopwords): ['rekomendasi', 'cs', 'nya', 'beli', 'obat', 'konfirmasi', 'jam', 'apotiknya', 'sampe', 'tutup', 'kunjung', 'dikirim', 'jam', 'kurir', 'sampe', 'ganti', 'berulangkali', 'sayang', 'ga', 'menu', 'pembatalan']\n",
            "\n",
            "\n",
            "Original Tokenized Text: ['baru', 'seminggu', 'd', 'updatesudah', 'minta', 'update', 'lagiheran', 'padahal', 'gk', 'ada', 'yg', 'baru', 'dari', 'aplikasi', 'nymasih', 'tetap', 'begitu', 'aja', 'kirain', 'update', 'ada', 'fitur', 'yg', 'terbaruternyata', 'tidakjadi', 'yg', 'd', 'update', 'itu', 'apa', 'tolong', 'lebih', 'd', 'perhatikan', 'kenapa', 'selalu', 'minta', 'update']\n",
            "Filtered Text (No Stopwords): ['seminggu', 'updatesudah', 'update', 'lagiheran', 'gk', 'aplikasi', 'nymasih', 'kirain', 'update', 'fitur', 'terbaruternyata', 'tidakjadi', 'update', 'tolong', 'perhatikan', 'update']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan hasil stopword removal ke dalam file CSV\n",
        "df.to_csv('/content/filtered_riview.csv', index=False)\n",
        "# Memberikan pesan bahwa file telah disimpan\n",
        "print(\"Hasil stopword removal telah disimpan ke dalam '/content/filtered_riview.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yo18MbpWJBp",
        "outputId": "5bf6fa74-0aef-4df3-963e-f192208b8b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil stopword removal telah disimpan ke dalam '/content/filtered_riview.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Stemming"
      ],
      "metadata": {
        "id": "VVggbxfZW0HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemmingText(text):\n",
        "    # Membuat objek stemmer\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    words = text.split()   # Memecah teks menjadi daftar kata\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]  # Menerapkan stemming pada setiap kata dalam daftar\n",
        "    stemmed_text = ' '.join(stemmed_words) # Menggabungkan kata-kata yang telah distem\n",
        "    return stemmed_text"
      ],
      "metadata": {
        "id": "i6Z9iYCcXLgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "def stemmingText(text_list):\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "\n",
        "    # Pastikan input berupa list\n",
        "    if isinstance(text_list, list):\n",
        "        stemmed_words = [stemmer.stem(word) for word in text_list]  # Stemming per kata dalam list\n",
        "        return stemmed_words  # Kembalikan sebagai list (atau bisa di-join jadi string jika perlu)\n",
        "    else:\n",
        "        return text_list  # Jika bukan list, kembalikan tanpa perubahan\n",
        "\n",
        "# Terapkan stemming pada kolom 'filtered_riview'\n",
        "df['stemmed_riview'] = df['filtered_riview'].apply(stemmingText)\n",
        "# Tampilkan hasilnya untuk verifikasi\n",
        "print(df[['stemmed_riview']].head(10))\n",
        "\n",
        "# Simpan hasilnya ke file CSV\n",
        "output_file = \"stemmed_reviews.csv\"  # Nama file keluaran\n",
        "df.to_csv(output_file, index=False)  # Simpan tanpa menyertakan indeks\n",
        "print(f\"Hasil stemming telah disimpan ke file: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ofWfEqTdJUk",
        "outputId": "12add6f4-2d6d-42d3-e480-8b703801bb47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      stemmed_riview\n",
            "0  [buruk, mana, orang, pesan, karna, butuh, cepa...\n",
            "1  [gk, efektif, resep, obat, tebus, pakai, aplik...\n",
            "2  [apk, alami, error, mana, konfirmasi, bayar, u...\n",
            "3  [rekomendasi, cs, nya, beli, obat, konfirmasi,...\n",
            "4  [minggu, updatesudah, update, lagiheran, gk, a...\n",
            "5  [kasih, bintang, aplikasi, bagus, mudah, pakai...\n",
            "6  [aplikasi, nya, mudah, berat, android, versi, ...\n",
            "7  [aplikasi, bermanfaatmendukungmudah, cari, art...\n",
            "8  [aplikasi, bagus, manfaat, orang, terima, kasi...\n",
            "9  [bantu, org, tua, muda, alam, kembang, anak, r...\n",
            "Hasil stemming telah disimpan ke file: stemmed_reviews.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Pelabelan (Tahap pelabelan dilakukan oleh pakar bahasa)"
      ],
      "metadata": {
        "id": "MH9QdsIOZTug"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Membaca file CSV dengan opsi on_bad_lines='skip' untuk mengabaikan baris yang bermasalah\n",
        "df = pd.read_csv('/content/drive/MyDrive/stemmed_reviews_pakar_INDO.csv',\n",
        "                 sep=';',  # Ganti sesuai dengan pemisah yang benar\n",
        "                 on_bad_lines='skip')\n",
        "\n",
        "# Menampilkan beberapa baris pertama DataFrame\n",
        "print(df.head())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KWOpAjneJGuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256599b7-d802-427b-fc6a-9b8c642c0b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             stemmed_riview;sentimen\n",
            "0  ['buruk', 'pesan', 'butuh', 'cepat', 'aplikasi...\n",
            "1  ['efektif', 'resep', 'obat', 'tebus', 'pakai',...\n",
            "2  ['apk', 'alami', 'error', 'konfirmasi', 'bayar...\n",
            "3  ['rekomendasi', 'cs', 'beli', 'obat', 'konfirm...\n",
            "4  ['minggu', 'updatesudah', 'update', 'lagiheran...\n"
          ]
        }
      ]
    }
  ]
}